[{"id":0,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Linux_%E5%B0%8F%E6%8A%80%E5%B7%A7%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/","title":"Linux 小技巧(持续更新)【置顶】","section":"网络与运维","content":"Linux 小技巧(持续更新)\r#\r\r2020-09-26 13:24\n 使用软连接将nginx 作为系统命令。其他软件命令同理  ln /usr/local/nginx/sbin/nginx /usr/sbin/nginx\r查看系统版本  cat /etc/issue\r查看CPU核数  cat /proc/cpuinfo |grep \u0026quot;cpu cores\u0026quot;|uniq\r查看内存  cat /proc/meminfo |grep MemTotal\r 定时任务crontab\n 当前的定时任务 crontab -l 编辑定时任务 crontab -e    tar 文件分割与合并\n  分割\nsplit -b 40M -d -a 2 test.tar.gz test.tar.gz.\r 参数含义： -b：指定每个文件的大小，单位可以为B、K、M ； -d：使用数字而不是字母作为后缀名 ； -a：后缀名长度，默认为2；\n ​\t合并\ncat test.tar.gz.* \u0026gt; test_new.tar.gz\r 删除find 出来的文件\nfind . -name *Test* -type f | xargs rm -f 同理，压缩find 出来的文件\nfind .name *Test* -type f | xargs zip text.zip   开机自动挂载\n修改/etc/fstab\n111.111.111.111:/data /target/data nfs defaults   查看某个网络相关操作用到的端口\n有个mount nfs 服务一直失败，提示超时之类的，这类错误基本可以确定是网络权限导致的异常了。\n开通nfs 服务常用的2049，111端口之后，还是超时。还有端口没开通？这时用netstat 可以确认哪个端口正在使用\nnetstat -an |grep {nfs服务ip} 所以，以后遇到有啥服务访问不通时，可以用上述命令检查是何端口导致。\n  允许非root 用户使用1024以下的端口号\n即时生效：sysctl net.ipv4.ip_unprivileged_port_start=0\n重启生效：echo \u0026quot;net.ipv4.ip_unprivileged_port_start=0\u0026quot; \u0026gt;\u0026gt; /etc/sysctl.conf\n  wget 下载文件\nwget -O {文件名} {下载链接} 可以下载文件，不过有时候会遇到文件下载接口启用了gzip，此时下载可能会出现文件不完整的情况，导致文件无法打开。此时，下载下载的应该是一个gzip文件，所以我们在原文件名指定多一个文件后缀。\nwget -O {文件名}.gz {下载链接} ，下载下来之后，使用gunzip {文件名}.gz进行解压，就可以得到原文件了。\n  "},{"id":1,"href":"/docs/%E6%88%91%E7%88%B1%E7%BC%96%E7%A8%8B/%E4%BD%BF%E7%94%A8_SpringCloud_Config_%E4%BD%9C%E4%B8%BA%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/","title":"使用 SpringCloud Config 作为配置中心","section":"我爱编程","content":"使用 SpringCloud Config 作为配置中心\r#\r\r2022-01-01 08:57\n一开始调研的是阿里的Nacos，花了些时间装上服务端，增加一个配置文件。客户端要调用的时候，启动怎么都是失败，提示某个类未找到。搜索后，在官方仓库的issue上，发现不止笔者一个人遇到这个问题\r升级Spring 2.4.1 ConfigurationBeanFactoryMetadata 找不到。好家伙，一年多了，这issue还挂着。SpringBoot 都2.6版本了，2.4版本居然还不支持。好像有人说，阿里的开源项目都是kpi项目？放弃。\n后面又稍微看了下Apollo，是携程的。但始终不放心，这要是也用着用着，就流产了，那咋搞？要不，还是用回官方的SpringCloud Config 吧。\n老实说，SpringCloud Config 的官方文档也实在是不清晰。好在网上文章不少。结合实践，几个小时下来算是把项目搭建起来了。\nConfig Server\r#\r\r创建一个普通的SpringBoot 项目。 如果使用默认的Git 作为Config Server 的存储方式，那只需要一个依赖即可。\n\u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-config-server\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 项目配置，application.yaml\nserver: port: 8001 spring: application: name: configServer cloud: config: server: git: ## 此处配置Git 仓库地址；如果是私有仓库，需要配置账号密码 uri: https://gitee.com/cevin15/config.git username: xxx password: xxx 项目启动类，ConfigerApplication.java\n@EnableConfigServer @SpringBootApplication public class ConfigServerApplication { public static void main(String[] args) { SpringApplication.run(ConfigServerApplication.class, args); } } 在Git 仓库中上传一个配置文件configClient-test.yaml，configClient 为客户端项目的application name，test 为客户端项目的profile。\nserver: port: 8008 访问\rlocalhost:8001/configClient-test.yaml，响应如下，说明Config Server 启动成功\nserver: port: 8008 Config Client\r#\r\r创建一个普通的SpringBoot 项目。 添加依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-bootstrap\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.cloud\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-cloud-starter-config\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 这里要注意，SpringBoot 在2.4版本之后，需要添加bootstrap 依赖，项目才能读取bootstrap 启动文件 项目配置，bootstrap.yaml\nserver: port: 8080\t##增加一个与配置中心配置不一致的端口，看看最终使用哪个:-) spring: application: name: configClient cloud: config: label: main profile: test uri: http://localhost:8001 启动项目，应用端口号 8008，说明参数已经成功注入。\nINFO - 28460 Fetching config from server at : http://localhost:8001 INFO - 28460 Located environment: name=configClient, profiles=[test], label=main, version=e06de6240b98bc9c9fad29692d31e59c8ce2d793, state=null INFO - 28460 Located property source: [BootstrapPropertySource {name=\u0026#39;bootstrapProperties-configClient\u0026#39;}, BootstrapPropertySource {name=\u0026#39;bootstrapProperties-https://gitee.com/cevin15/config.git/file:C:\\Users\\xxxx\\AppData\\Local\\Temp\\config-repo-8787147078801297440\\configClient-test.yaml\u0026#39;}] INFO - 28460 No active profile set, falling back to default profiles: default INFO - 28460 BeanFactory id=2c1fe4dd-1f53-3283-bcc7-3096bc8368a3 INFO - 28460 Tomcat initialized with port(s): 8008 (http) INFO - 28460 Starting service [Tomcat] INFO - 28460 Starting Servlet engine: [Apache Tomcat/9.0.56] INFO - 28460 Initializing Spring embedded WebApplicationContext INFO - 28460 Root WebApplicationContext: initialization completed in 2556 ms INFO - 28460 Tomcat started on port(s): 8008 (http) with context path \u0026#39;\u0026#39; INFO - 28460 Started ConfigClientApplication in 10.73 seconds (JVM running for 11.615) 支持JDBC 的Config Server\r#\r\rSpringCloud Config 除了Git，还支持数据库存储配置信息。我们只需要一个表，5个字段即可。 我们使用数据库作为存储库，在ConfigServer项目中添加如下数据库依赖\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-jdbc\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;mysql\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;mysql-connector-java\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;8.0.25\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 修改项目配置，application.yaml\nserver: port: 8001 spring: application: name: configServer profiles: active: jdbc ##此次修改为jdbc，默认为git cloud: config: server: jdbc: ## Config Server 默认使用此Sql 读取配置 sql: select c_key, c_value from configer where c_application=? and c_profile=? and c_label=? datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://localhost:3306/config username: xxx password: xxx Config Server 默认使用此Sql 读取配置。现在建一个库config，表configer，然后添加一条数据：\nCREATE TABLE `configer` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c_key` varchar(255) DEFAULT NULL, `c_value` varchar(255) DEFAULT NULL, `c_application` varchar(255) DEFAULT NULL, `c_profile` varchar(255) DEFAULT NULL, `c_label` varchar(255) DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4; // 端口我们使用8009，跟Git 的配置区分下 INSERT INTO `configer` VALUES (\u0026#39;1\u0026#39;, \u0026#39;server.port\u0026#39;, \u0026#39;8009\u0026#39;, \u0026#39;configClient\u0026#39;, \u0026#39;test\u0026#39;, \u0026#39;main\u0026#39;);\t启动server项目，不改动client项目，重新启动，响应如下，发现client 使用了8009端口，JDBC 版本的Config Server 启动成功了。\nINFO - Fetching config from server at : http://localhost:8001 INFO - Located environment: name=configClient, profiles=[test], label=main, version=null, state=null INFO - Located property source: [BootstrapPropertySource {name=\u0026#39;bootstrapProperties-configClient\u0026#39;}, BootstrapPropertySource {name=\u0026#39;bootstrapProperties-configClient-test\u0026#39;}] INFO - No active profile set, falling back to default profiles: default INFO - BeanFactory id=2c1fe4dd-1f53-3283-bcc7-3096bc8368a3 INFO - Tomcat initialized with port(s): 8009 (http) INFO - Starting service [Tomcat] INFO - Starting Servlet engine: [Apache Tomcat/9.0.56] INFO - Initializing Spring embedded WebApplicationContext INFO - Root WebApplicationContext: initialization completed in 2332 ms INFO - Tomcat started on port(s): 8009 (http) with context path \u0026#39;\u0026#39; INFO - Started ConfigClientApplication in 10.394 seconds (JVM running for 11.243) 总结\r#\r\rSpring Cloud Config 作为官方出品的配置中心，使用简单，拓展性强，而且升级有保障，很是推荐:-)\n文章中的项目已提交到\rGitee，有需要可以参考。\n"},{"id":2,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/%E8%BD%ACHyper-v%E4%B8%ADCentOS-7%E7%9A%84%E9%9D%99%E6%80%81%E7%BD%91%E7%BB%9C%E4%B8%8E%E5%8A%A8%E6%80%81%E7%BD%91%E7%BB%9C%E9%85%8D%E7%BD%AE%E5%8F%8ASSH%E8%BF%9E%E6%8E%A5%E5%B0%8F%E8%AE%B0/","title":"【转】Hyper-v中CentOS-7的静态/动态网络配置及SSH连接小记","section":"网络与运维","content":"【转】Hyper-v中CentOS-7的静态/动态网络配置及SSH连接小记\r#\r\r2023-06-20 18:29\n 原文：\rHyper-v中CentOS-7的静态/动态网络配置及SSH连接小记\n 需求\r#\r\r 本地win10 hyper-v中安装centos7，centos7可连接外网通过yum下载各种包 centos7拥有静态ip，可以稳定的通过ssh工具（例如xshell）链接  思路\r#\r\r使用双网卡，一个负责外网，一个负责内网：\n 使用hyper-v自带默认虚拟交换机default switch的网卡自动获取外网连接 新建内部虚拟交换机与新建网卡相关联，配置静态ip，供SSH连接  步骤\r#\r\r  新建类型为“内部”的虚拟交换机   在“控制面板-网络连接”中设置此交换机地址，名字：ssh-connect   虚拟机关机前提下，为虚拟交换机新建网卡。（右键虚拟机-设置）   第一块网卡关联default switch，第二块关联新建的虚拟交换机   打开虚拟机，虚拟机内设置两块网卡的网络\n配置eth0\n在虚拟机中编辑/etc/sysconfig/network-scripts/ifcfg-eth0，把BOOTPROTO改为dhcp，ONBOOT改为yes：\n[root@localhost ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0\rTYPE=Ethernet\rPROXY_METHOD=none\rBROWSER_ONLY=no\rBOOTPROTO=dhcp\rDEFROUTE=yes\rIPV4_FAILURE_FATAL=no\rIPV6INIT=yes\rIPV6_AUTOCONF=yes\rIPV6_DEFROUTE=yes\rIPV6_FAILURE_FATAL=no\rIPV6_ADDR_GEN_MODE=stable-privacy\rNAME=eth0\rUUID=ec60946a-e236-4735-8bac-dd97dcd3d469\rDEVICE=eth0\rONBOOT=yes\r配置eth1\n拷贝ifcfg-eth0，并改名为ifcfg-eth1。修改BOOTPROTO为static，把NAME和DEVICE改为eth1，删除UUID（不能和eth0相同）。\n加上IPADDR=192.168.218.2和NETMASK=255.255.255.0，IP必须与ssh-connect一个网段，不用设置GATEWAY\n[root@localhost ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth1\rTYPE=Ethernet\rPROXY_METHOD=none\rBROWSER_ONLY=no\rBOOTPROTO=static\rDEFROUTE=yes\rIPV4_FAILURE_FATAL=no\rIPV6INIT=yes\rIPV6_AUTOCONF=yes\rIPV6_DEFROUTE=yes\rIPV6_FAILURE_FATAL=no\rIPV6_ADDR_GEN_MODE=stable-privacy\rNAME=eth1\rDEVICE=eth1\rONBOOT=yes\rIPADDR=192.168.218.2\rNETMASK=255.255.255.0\r  重启网络service network restart，之后就可以ping 通www.baidu.com\n[root@localhost ~]# ping -c 5 www.baidu.com\rPING www.a.shifen.com (14.119.104.189) 56(84) bytes of data.\r64 bytes from 14.119.104.189 (14.119.104.189): icmp_seq=1 ttl=54 time=9.79 ms\r64 bytes from 14.119.104.189 (14.119.104.189): icmp_seq=2 ttl=54 time=9.33 ms\r64 bytes from 14.119.104.189 (14.119.104.189): icmp_seq=3 ttl=54 time=20.5 ms\r64 bytes from 14.119.104.189 (14.119.104.189): icmp_seq=4 ttl=54 time=12.7 ms\r64 bytes from 14.119.104.189 (14.119.104.189): icmp_seq=5 ttl=54 time=8.17 ms\r--- www.a.shifen.com ping statistics ---\r5 packets transmitted, 5 received, 0% packet loss, time 4075ms\rrtt min/avg/max/mdev = 8.177/12.124/20.557/4.480 ms\r主机可以通过192.168.218.2 连接虚拟机   "},{"id":3,"href":"/docs/%E6%88%91%E7%88%B1%E7%BC%96%E7%A8%8B/%E4%B8%8D%E9%87%8D%E5%90%AFJava-%E8%BF%9B%E7%A8%8B%E5%AF%BC%E5%87%BAdump_%E6%96%87%E4%BB%B6%E7%9A%84%E6%96%B9%E6%B3%95/","title":"不重启Java 进程，导出dump 文件的方法","section":"我爱编程","content":"CentOS 7.x 扩容\r#\r\r2022-05-26 09:27\n不重启Java 进程，导出dump 文件的方法\r#\r\r首先，查看gc 情况：jstat -gcutil $pid $time\n$ jstat -gcutil $pid $time\rS0 S1 E O M CCS YGC YGCT FGC FGCT GCT\r0.00 100.00 12.91 61.13 96.44 93.83 201 56.754 4 58.699 115.453\r0.00 100.00 4.25 51.06 96.44 93.83 202 56.783 4 58.699 115.482\r0.00 100.00 10.68 60.63 96.44 93.83 202 56.783 4 58.699 115.482\r手动导出当前时点的dump 文件\r#\r\rjmap -dump:format=b,file=$dump_file_path $pid\r另一种方式：\njcmd $pid GC.heap_dump -all $dump_file_path\r在jvm 发生异常时，自动导出dump 文件\r#\r\r  查看jinfo 可以调整的参数：java -XX:+PrintFlagsFinal -version|grep manageable\n$ java -XX:+PrintFlagsFinal -version|grep manageable\r……\rbool HeapDumpAfterFullGC = false {manageable}\rbool HeapDumpBeforeFullGC = false {manageable}\rbool HeapDumpOnOutOfMemoryError = false {manageable}\rccstr HeapDumpPath = {manageable}\r……\r主要关注以上几个参数：\n FullGC 前导出：HeapDumpBeforeFullGC FullGC 后导出：HeapDumpAfterFullGC 发生OutOfMemory 时导出：HeapDumpOnOutOfMemoryError dump文件保存目录：HeapDumpPath    设置jvm参数，fullgc前dump 文件：jinfo -flag +HeapDumpBeforeFullGC $pid\n  设置dump文件保存目录：jinfo -flag HeapDumpPath=$file_path $pid\n  查看jinfo设置的参数值：jinfo -flag $param_name $pid，比如jinfo -flag HeapDumpPath 9846\n  分析dump 文件\r#\r\r使用\rMAT 查看分析dump文件，通常使用这两个菜单。\n Histogram: Lists number of instances per class\nDominator Tree: List the biggest objects and what they keep alive.\n "},{"id":4,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/%E4%BD%BF%E7%94%A8_Keepalived_%E5%AE%9E%E7%8E%B0_Nginx_%E5%8F%8C%E6%9C%BA%E7%83%AD%E5%A4%87/","title":"使用Keepalived 实现Nginx 双机热备","section":"网络与运维","content":"使用Keepalived 实现Nginx 双机热备\r#\r\r2021-12-01 20:05\nNginx 安装\r#\r\r首先准备两台服务器，上面均部署Nginx。\n参考这里\rLinux 的 Nginx 安装【转】\nKeepalived 安装\r#\r\ryum install -y keepalived Keepalived 配置\r#\r\r简单模式\r#\r\r目录 /etc/keepalived/keepalived.conf\n! Configuration File for keepalived global_defs { #路由id，全局唯一，表示当前keepalived节点的唯一性 router_id keep_15 } vrrp_instance VI_1 { #设置当前实例状态为MASTER。MASTER代表是主实例，BACKUP代表是备用实例 state BACKUP #当前实例绑定的网卡 interface eth0 #当前实例的虚拟路由id，一组主备的实例的路由id是相同的 virtual_router_id 101 #当前实例的优先级 priority 100 #主备之间同步检查时间间隔 advert_int 1 #一组主备实例的认证密码，方式非法节点进入路由组 authentication { auth_type PASS auth_pass 123456Qw } #设置当前实例的虚拟IP virtual_ipaddress { 192.168.137.101 dev eth0 } } 主备的Nginx 服务器上，均使用该配置，调整router_id即可。网卡名eth0记得跟改为服务器上的网卡名。\n重启Keepalived：systemctl restart keepalived。轮流关闭Keepalived，可以发现虚拟IP192.168.137.101在两台主机上进行漂移。\n应对主备机某些情况下单机不可用的情况，Keepalived 这样已经够用了。任意机器挂掉，都能保障192.168.137.101是可用的。\n有时候，我们还想使用脚本做一些更高阶的操作。比如说，Keepalived 定时检查业务进程，如果进程挂掉尝试重启，重启失败则主动kill 自身，让虚拟IP 飘逸到另外一台机器上。可以参考如下配置。\n增加check 操作的模式\r#\r\r首先，我们增加在/data/sh下增加一个脚本文件：check_nginx.sh\n#!/bin/bash status=$(ps -C nginx --no-heading|wc -l) if [ \u0026#34;${status}\u0026#34; = \u0026#34;0\u0026#34; ]; then /usr/sbin/nginx status2=$(ps -C nginx --no-heading|wc -l) if [ \u0026#34;${status2}\u0026#34; = \u0026#34;0\u0026#34; ]; then systemctl stop keepalived fi fi 该脚本的工作就是检查Nginx 进程是否存在，不存在则尝试重启，重启失败则停止Keepalived。\n然后，我们调整/etc/keepalived/keepalived.conf\n! Configuration File for keepalived global_defs { # 路由id，全局唯一，表示当前keepalived节点的唯一性 router_id keep_14 # 执行script 的用户 script_user root } vrrp_script chk_nginx { script \u0026#34;/data/sh/check_nginx.sh\u0026#34; # 5秒检查一次 interval 5 # 每次操作可以增减权重，这里我们置为0，先不使用 weight 0 } vrrp_instance VI_1 { #设置当前实例状态为MASTER。MASTER代表是主实例，BACKUP代表是备用实例 state BACKUP #当前实例绑定的网卡 interface eth0 #当前实例的虚拟路由id，一组主备的实例的路由id是相同的 virtual_router_id 101 #当前实例的优先级 priority 100 #主备之间同步检查时间间隔 advert_int 5 #一组主备实例的认证密码，方式非法节点进入路由组 authentication { auth_type PASS auth_pass 123456Qw } #设置当前实例的虚拟IP virtual_ipaddress { 192.168.137.101 dev eth0 } track_script { chk_nginx } } 这个配置有两个地方要注意的。\n script_user：执行脚本的用户，这里简单设置为了root。为了安全起见，可以专门增加一个别的用户来执行脚本。 关闭selinux，如不关闭，查看/var/log/messages会看到这么一个错误：Unable to access script  手动关闭setlinux：setenforce 0 永久关闭，修改文件/etc/sysconfig/selinux：SELINUX=disabled    好了，重启Keepalived，即可看到效果了：关闭Nginx，几秒后，Nginx 就被重启起来了。\n SELinux(Security-Enhanced Linux) 是\r美国国家安全局（NSA）对于\r强制访问控制的实现，它是一个 Linux 内核模块，也是 Linux 的一个安全子系统。\nSELinux 主要作用就是最大限度地减小系统中服务进程可访问的资源（最小权限原则）。\n "},{"id":5,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Linux_%E9%98%B2%E7%81%AB%E5%A2%99_Firewalld_%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C/","title":"Linux 防火墙 Firewalld 使用过的经验","section":"网络与运维","content":"Linux 防火墙 Firewalld 使用过的经验\r#\r\r2021-04-01 15:46\n目前使用经验适用于CentOS 7+，Redhat 7+\n有些系统没有默认安装Firewalld，可以使用yum进行安装：yum install -y firewalld\nFirewalld 状态查询\n[root@Genl-gm-4885 ~]# firewall-cmd --state not running Firewalld 启用，关闭等等命令\nsystemctl start firewalld //启动 systemctl stop firewalld //停用 systemctl enable firewalld //设置Firewalld自启动 systemctl disable firewalld //设置Firewalld不自启动 PS. 查看系统自启动服务\nsystemctl list-unit-files|grep enabled Firewalld 使用了zone的一个概念，通过设置zone 可以快速设置防火墙的规则。\n使用firewall-cmd --get-zones 获取zone列表\nblock dmz drop external home internal public trusted work 默认的zone 是public。拒绝所有的连接请求，除了dhcp和ssh。\nzone=trusted 则相反，为接受所有请求。\n获取当前使用的zones\nfirewall-cmd --get-active-zones\t切换到别的zone\nfirewall-cmd --zone=trusted --change-interface=#{网卡名，如eth190} Firewalld 的连接规则有三类：\n drop：抛弃连接请求 reject：拒绝连接请求 accept：接受连接请求  使用rich rule 添加防火墙规则\nfirewall-cmd --zone=public --add-rich-rule \u0026#39;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;172.255.92.199\u0026#34; accept\u0026#39; --permanent //添加 permanent，表明永久有效，但需要reload firewall-cmd --reload //reload 规则 查看当前规则\nfirewall-cmd --list-all 举个例子，假设要禁用 172.253.0.0/16 网段，但允许172.253.32.21 访问。\n理所当然的这么调整，发现不行；调换顺序也不行。\nfirewall-cmd --zone=public --add-rich-rule \u0026#39;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;172.253.0.0/16\u0026#34; reject\u0026#39; --permanent firewall-cmd --zone=public --add-rich-rule \u0026#39;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;172.253.32.21\u0026#34; accept\u0026#39; --permanent 翻了N久的bing和百度，没找到任何说法。后来发现了NOT 语法！\n如下这番，就可以了！！\nfirewall-cmd --zone=public --add-rich-rule \u0026#39;rule family=\u0026#34;ipv4\u0026#34; source NOT address=\u0026#34;172.253.0.0/16\u0026#34; accept\u0026#39; --permanent firewall-cmd --zone=public --add-rich-rule \u0026#39;rule family=\u0026#34;ipv4\u0026#34; source address=\u0026#34;172.253.32.21\u0026#34; accept\u0026#39; --permanent PS.一些字段掩码的规则\n172.0.0.0/8：代表 172.0.0.1 - 172.255.255.255\n172.23.0.0/16：代表 172.23.0.1 - 172.23.255.255\n172.23.15.0/24：代表 172.23.15.1 - 172.23.15.255\n"},{"id":6,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Kubernetes_%E4%B8%8EDocker_%E4%BD%BF%E7%94%A8%E7%BB%8F%E9%AA%8C/","title":"Kubernetes 与 Docker 使用经验","section":"网络与运维","content":"Kubernetes 与 Docker 使用经验\r#\r\r2021-09-29 13:43\n使用docker login 登录私有仓库\r#\r\rdocker login --username=${用户名} ${私有仓库地址}\rDocker会将token存储在~/.docker/config.json文件中，从而作为拉取私有镜像的凭证。\n推送docker镜像到私有仓库\r#\r\r先打上私有仓库的标签\ndocker tag demo:0.0.1 ${私有仓库地址}/demo:0.0.1\r推送\ndocker push ${私有仓库地址}/demo:0.0.1\rkubernetes 拉取私有仓库镜像\r#\r\r生成私有仓库secret\nkubectl create secret docker-registry ${secret名} --docker-server=${私有仓库地址} --docker-username=${用户名} --docker-password=${用户密码} --docker-email=${用户邮箱}\ryaml 文件拉取镜像时使用secret\n ## 配置如下\rspec:\rcontainers:\r- name: demo\rimage: xxx/demo:0.0.1\rports:\r- containerPort: 8015\rimagePullSecrets: # 使用secret 拉取私有仓库数据\r- name: ${secret名} # 上述步骤生成的secret名\r进入容器内部\r#\r\rkubectl exec -it ${pod name} -- /bin/bash\rkubernetes 的kubeconfig 文件\r#\r\rkubeconfig 保存为~/.kube/config ，作为默认文件。指定某个config文件语法为 \u0026ndash;kubeconfig=${config 文件路径}\nkubernetes 污点node 的处理\r#\r\rkubectl describe node ${node name} |grep NoSchedule\rkubectl taint node ${node name} {上面查出来的value}\r"},{"id":7,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Linux_%E4%BD%BF%E7%94%A8chkconfig_%E5%AE%9E%E7%8E%B0%E6%9C%8D%E5%8A%A1%E8%87%AA%E5%90%AF%E5%8A%A8/","title":"Linux 使用chkconfig 实现服务自启动","section":"网络与运维","content":"Linux 使用chkconfig 实现服务自启动\r#\r\r2021-06-15 15:44\n查看服务\r#\r\rchkconfig --list 自定义服务\r#\r\r在/etc/init.d/目录下，添加自定义的脚本文件。\n脚本文件有个要注意的地方，需要在文件开头定义如下内容。如果没有，可能会报这个错误：service ${service_name} does not support chkconfig\n# chkconfig: 2345 91 89 # description: ${service_name} 第一行表示 chkconfig的规则，2345 启动级别，91 启动优先级，89 关闭优先级（优先级 0-100，值越高优先级越低）\n举个例子子，如下为笔者配置的elasticsearch 自启脚本。P.S. 这里使用es 用户来启动elasticsearch。\n#! /bin/bash # elasticsearch # chkconfig: 2345 91 89 # description: elasticsearch su - es -c \u0026#34;source /etc/profile \u0026amp;\u0026amp; /usr/es/elasticsearch-6.5.4/bin/elasticsearch -d\u0026#34; 最后，给这个脚本添加执行权限：chmod +x elasticsearch\n添加服务\r#\r\rchkconfig --add ${service_name}\t如果如上已经配置了2345的启动级别，则默认添加之后就设置了自启动。\n关闭服务自启动\r#\r\rchkconfig ${service_name} off 默认level 是2345，可以使用--level 指定level\n启动服务自启动\r#\r\rchkconfig ${service_name} on 默认level 是2345，可以使用--level 指定level\n"},{"id":8,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Linux_%E8%87%AA%E5%AE%9A%E4%B9%89%E6%9C%8D%E5%8A%A1/","title":"Linux 自定义服务","section":"网络与运维","content":"Linux 自定义服务\r#\r\r2021-06-08 00:18\n晚上抽空学了下在Linux 服务器中自定义service，自定义之后，启动、停止、开机自启动等操作就简单多了。\n我们以tomcat 作为我们的例子，目标是将tomcat 自定义为service，并实现开机自启动。\n准备工作\r#\r\r 系统版本 CentOS 7.x 配置好JDK，下载Tomcat，并找个目录解压 执行下Tomcat bin目录下的startup.sh，shutdow.sh 命令，确认环境是否正确  Show Time\r#\r\r首先，在目录/usr/lib/systemd/system 中创建一个service文 件：tomcat.service，内容如下：\n[Unit] Description=apache tomcat service [Service] Type=simple ExecStart=/usr/local/tomcat/apache-tomcat-10.0.6/bin/auto_startup.sh ExecStop=/usr/local/tomcat/apache-tomcat-10.0.6/bin/auto_shutdown.sh RemainAfterExit=yes [Install] WantedBy=multi-user.target Service 文件中各个节点的含义就不深入讲了（笔者也还只是懂些皮毛），说下两点要注意的。\n  没有直接使用Tomcat bin目录下的startup.sh，shutdow.sh 命令，因为会提示JAVA_HOME，JRE_HOME 找不到，所以自定义了两个sh文件，内容如下：\n#!/bin/sh source /etc/profile /usr/local/tomcat/apache-tomcat-10.0.6/bin/startup.sh #!/bin/sh source /etc/profile /usr/local/tomcat/apache-tomcat-10.0.6/bin/shutdown.sh 增加了source /etc/profile，先加载了Java的环境变量。\n某些时候，还会提示配置文件找不到（如果类中有根据相对路径来查找文件的代码的话），导致Tomcat 启动失败。那我们可以这样来写启动脚本：\n#!/bin/sh source /etc/profile cd /usr/local/tomcat/apache-tomcat-10.0.6/bin ./startup.sh   注意RemainAfterExit=yes，未增加该配置之前，执行systemctl start tomcat.service总是执行完start之后，立刻又执行stop。\n  接着，见证奇迹的时刻了。\nsystemctl start tomcat.service，可以发现Tomcat启动了。\nsystemctl enable tomcat.service，重启服务器，发现Tomcat 自启动了。\nEnjoy it :-)\nP.S. 服务相关的一些命令，作为备忘\n# 启动 systemctl start tomcat.service # 停止 systemctl stop tomcat.service # 开机自启动 systemctl enable tomcat.service # 取消开机自启动 systemctl disable tomcat.service # 查看systemctl 的日志 journalctl -u tomcat.service # 修改了tomcat.service，需要重载文件 systemctl daemon-reload # 查看系统自启动的服务 systemctl list-unit-files|grep enabled "},{"id":9,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Nginx_%E6%AD%A3%E5%90%91%E4%BB%A3%E7%90%86%E8%AE%A9%E5%86%85%E7%BD%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%94%AF%E6%8C%81%E4%B8%8A%E7%BD%91/","title":"Nginx 正向代理——让内网服务器支持上网","section":"网络与运维","content":"Nginx 正向代理——让内网服务器支持上网\r#\r\r2020-12-15 17:44\n假设我们有两台机器A和B，A能上网，B不能上网，B能连通A的某个端口，比如说80，443。在A上安装Nginx，并且通过Nginx的正向代理，达到B能上网的目的。\nA机器上的操作\r#\r\rNginx 编译安装需要增加一个插件 https://github.com/chobits/ngx_http_proxy_connect_module\n 在官方的Github上找到合适的ngx_http_proxy_connect_module 插件版本     nginx version enable REWRITE phase patch     1.4.x ~ 1.12.x NO proxy_connect.patch   1.4.x ~ 1.12.x YES proxy_connect_rewrite.patch   1.13.x ~ 1.14.x NO proxy_connect_1014.patch   1.13.x ~ 1.14.x YES proxy_connect_rewrite_1014.patch   1.15.2 YES proxy_connect_rewrite_1015.patch   1.15.4 ~ 1.16.x YES proxy_connect_rewrite_101504.patch   1.17.x ~ 1.18.0 YES proxy_connect_rewrite_1018.patch     下载合适的版本，这里下载 proxy_connect_rewrite_1018.patch 上传插件到服务器，解压到某个目录，比如/usr/local/src 接下来就是编译安装的时候带上这个插件，如下是官方的例子。更详细的安装过程，可以参考这篇文章\rLinux的Nginx 安装  $ tar -xzvf nginx-1.9.2.tar.gz $ cd nginx-1.9.2/ $ patch -p1 \u0026lt; /path/to/ngx_http_proxy_connect_module/patch/proxy_connect.patch $ ./configure --add-module=/path/to/ngx_http_proxy_connect_module $ make \u0026amp;\u0026amp; make install  调整Nginx的配置，增加一个代理的server节点，如下。官方的例子做了小调整  server { listen 80; # dns resolver used by forward proxying resolver 8.8.8.8; # forward proxy for CONNECT request proxy_connect; proxy_connect_allow 443 563; proxy_connect_connect_timeout 10s; proxy_connect_read_timeout 10s; proxy_connect_send_timeout 10s; # forward proxy for non-CONNECT request location / { proxy_pass http://$host; //http，可以增加一个server节点，支持https。 proxy_set_header Host $host; } } B机器上的操作\r#\r\r 增加系统参数，编辑/etc/profile，增加两行配置，假设我们A机器的IP为172.168.1.111，代理端口如上配置的是80  export http_proxy=172.168.1.111:80 export https_proxy=172.168.1.111:80  让配置生效source /etc/profile 接下来，见证奇迹的时刻。curl A机器上能访问的域名看下:-)  延伸\r#\r\r跑在B上的Java 应用，依然不能访问外网。我们可以通过增加如下的启动参数来让应用通过代理上网。\n-Dhttp.proxyHost=172.168.1.111 -Dhttp.proxyPort=80 如果需要访问https协议的站点，参数有些许不通\n-Dhttps.proxyHost=172.168.1.111 -Dhttps.proxyPort=80 "},{"id":10,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Linux_%E9%85%8D%E7%BD%AEIPv6%E7%BD%91%E7%BB%9C/","title":"Linux 配置IPv6网络","section":"网络与运维","content":"Linux 配置IPv6网络\r#\r\r2020-11-04 20:26\n  修改网卡配置文件\nvi /etc/sysconfig/network-scripts/ifcfg-eth1\n增加如下配置\nIPV6INIT=yes IPV6ADDR=fdff::251:10:254:251:109 IPV6PREFIX=64 IPV6_DEFAULTGW=fdff::251:10:254:251:254 IPV6_AUTOCONF=no IPV6_DEFROUTE=yes IPV6_FAILURE_FATAL=no   重启网络\nservice network restart\n  一般情况下到这里就差不多了。ifconfig 查看，可以看到已经有IPv6地址了：inet6 addr: fdff::251:10:254:251:109/64 Scope:Global\neth1 Link encap:Ethernet HWaddr 00:50:56:9A:7B:5B inet addr:10.254.251.109 Bcast:10.254.251.255 Mask:255.255.255.0 inet6 addr: fe80::250:56ff:fe9a:7b5b/64 Scope:Link inet6 addr: fdff::251:10:254:251:109/64 Scope:Global 但我这边遇到个问题，本机可以telnet通，但外网一直不行。经过排查，发现还有个IPv6的防火墙未关闭。\n service ip6tables status 查看IPv6 防火墙状态 service ip6tables stop 关闭IPv6 防火墙 chkconfig ip6tables off 永久关闭IPv6防火墙（避免开机自启动）  PS. IPv6 的ping 命令为 ping6，chkconfig --list 查看开机启动项\n"},{"id":11,"href":"/docs/%E6%88%91%E7%88%B1%E7%BC%96%E7%A8%8B/VSCode_%E7%A6%BB%E7%BA%BF%E5%AE%89%E8%A3%85%E6%8F%92%E4%BB%B6/","title":"VSCode 离线安装插件","section":"我爱编程","content":"VSCode 离线安装插件\r#\r\r2020-09-26 14:04\n 登录官方的插件商城：\rhttps://marketplace.visualstudio.com/ 搜索所需要的插件 在插件详情页，下载该插件的安装文件。下载下来一般是vsix文件，比如说这里下载了一个vscjava.vscode-maven-0.24.2.vsix 文件  将该文件拷贝到固定目录，习惯上会存到VSCode 安装目录下的bin目录，比如C:\\Users\\yangyingqiang\\AppData\\Local\\Programs\\Microsoft VS Code\\bin 在当前目录下使用终端执行插件安装脚本  code --install-extension vscjava.vscode-maven-0.24.2.vsix\r看到如下进度提示，即安装成功。  Installing extensions...\rExtension 'vscjava.vscode-maven-0.24.2.vsix' was successfully installed.\r"},{"id":12,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Linux_%E4%BD%BF%E7%94%A8logrotate_%E5%88%87%E5%89%B2nginx_%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6/","title":"Linux中使用logrotate 切割nginx 日志文件【转】","section":"网络与运维","content":"Linux中使用logrotate 切割nginx 日志文件【转】\r#\r\r2020-09-26 11:12\nLogrotate的介绍\r#\r\r显而易见，Logrotate是基于CRON来运行的，其脚本是「/etc/cron.daily/logrotate」：\n#!/bin/sh\r/usr/sbin/logrotate /etc/logrotate.conf\rEXITVALUE=$?\rif [ $EXITVALUE != 0 ]; then\r/usr/bin/logger -t logrotate \u0026quot;ALERT exited abnormally with [$EXITVALUE]\u0026quot;\rfi\rexit 0\r实际运行时，Logrotate会调用配置文件「/etc/logrotate.conf」：\n# see \u0026quot;man logrotate\u0026quot; for details\r# rotate log files weekly\rweekly\r# keep 4 weeks worth of backlogs\rrotate 4\r# create new (empty) log files after rotating old ones\rcreate\r# uncomment this if you want your log files compressed\r#compress\r# RPM packages drop log rotation information into this directory\rinclude /etc/logrotate.d\r# no packages own wtmp -- we'll rotate them here\r/var/log/wtmp {\rmonthly\rminsize 1M\rcreate 0664 root utmp\rrotate 1\r}\r# system-specific logs may be also be configured here.\r这里的设置可以理解为Logrotate的缺省值，当然了，可以我们在「/etc/logrotate.d」目录里放置自己的配置文件，用来覆盖Logrotate的缺省值。\nLogrotate的演示\n按天保存一周的Nginx日志压缩文件，配置文件为「/etc/logrotate.d/nginx」：\n/usr/local/nginx/logs/*.log {\rdaily\rdateext\rcompress\rrotate 7\rsharedscripts\rpostrotate\rkill -USR1 `cat /var/run/nginx.pid`\rendscript\r}\r如果你等不及CRON，可以通过如下命令来手动执行：\nshell\u0026gt; logrotate -f /etc/logrotate.d/nginx\r当然，正式执行前最好通过Debug选项来验证一下，这对调试也很重要：\nshell\u0026gt; logrotate -d -f /etc/logrotate.d/nginx\rBTW：类似的还有Verbose选项，这里就不多说了。\nLogrotate的疑问\n问题：sharedscripts的作用是什么？\n大家可能注意到了，我在前面Nginx的例子里声明日志文件的时候用了星号通配符，也就是说这里可能涉及多个日志文件，比如：access.log和error.log。说到这里大家或许就明白了，sharedscripts的作用是在所有的日志文件都轮转完毕后统一执行一次脚本。如果没有配置这条指令，那么每个日志文件轮转完毕后都会执行一次脚本。\n问题：rotate和maxage的区别是什么？\n它们都是用来控制保存多少日志文件的，区别在于rotate是以个数为单位的，而maxage是以天数为单位的。如果我们是以按天来轮转日志，那么二者的差别就不大了。\n问题：为什么生成日志的时间是凌晨四五点？\n前面我们说过，Logrotate是基于CRON运行的，所以这个时间是由CRON控制的，具体可以查询CRON的配置文件「/etc/crontab」，可以手动改成如23:59等时间执行：\nSHELL=/bin/bash\rPATH=/sbin:/bin:/usr/sbin:/usr/bin\rMAILTO=root\rHOME=/\r# run-parts\r01 * * * * root run-parts /etc/cron.hourly\r59 23 * * * root run-parts /etc/cron.daily\r22 4 * * 0 root run-parts /etc/cron.weekly\r42 4 1 * * root run-parts /etc/cron.monthly\r如果使用的是新版CentOS，那么配置文件为：/etc/anacrontab。\n问题：如何告诉应用程序重新打开日志文件？\n以Nginx为例，是通过postrotate指令发送USR1信号来通知Nginx重新打开日志文件的。但是其他的应用程序不一定遵循这样的约定，比如说MySQL是通过flush-logs来重新打开日志文件的。更有甚者，有些应用程序就压根没有提供类似的方法，此时如果想重新打开日志文件，就必须重启服务，但为了高可用性，这往往不能接受。还好Logrotate提供了一个名为copytruncate的指令，此方法采用的是先拷贝再清空的方式，整个过程中日志文件的操作句柄没有发生改变，所以不需要通知应用程序重新打开日志文件，但是需要注意的是，在拷贝和清空之间有一个时间差，所以可能会丢失部分日志数据。\nBTW：MySQL本身在support-files目录已经包含了一个名为mysql-log-rotate的脚本，不过它比较简单，更详细的日志轮转详见「Rotating MySQL Slow Logs Safely」。\n…\n熟悉Apache的朋友可能会记得cronolog，不过Nginx并不支持它，有人通过mkfifo命令曲线救国，先给日志文件创建管道，再搭配cronolog轮转，虽然理论上没有问题，但效率上有折扣。另外，Debian/Ubuntu下有一个简化版工具savelog，有兴趣可以看看。\n 作者：MrHamster\n链接：https://www.jianshu.com/p/ec7f1626a3d3\n来源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n "},{"id":13,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Linux_Nginx%E5%AE%89%E8%A3%85/","title":"Linux的Nginx 安装【转】","section":"网络与运维","content":"Linux的Nginx 安装【转】\r#\r\r2020-09-26 09:22\n转载自 Nginx 安装配置 - 菜鸟教程\nNginx\r#\r\rNginx(\u0026ldquo;engine x\u0026rdquo;)是一款是由俄罗斯的程序设计师Igor Sysoev所开发高性能的 Web和 反向代理 服务器，也是一个 IMAP/POP3/SMTP 代理服务器。\n在高连接并发的情况下，Nginx是Apache服务器不错的替代品。\nNginx 安装\r#\r\r一. 安装编译工具及库文件\nyum -y install make zlib zlib-devel gcc-c++ libtool 二. 首先要安装 PCRE\nPCRE 作用是让 Nginx 支持 Rewrite 功能。\n 下载 PCRE 安装包，下载地址： http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz  [root@bogon src]# cd /usr/local/src/ [root@bogon src]# wget http://downloads.sourceforge.net/project/pcre/pcre/8.35/pcre-8.35.tar.gz 解压安装包:  [root@bogon src]# tar zxvf pcre-8.35.tar.gz 进入安装包目录  [root@bogon src]# cd pcre-8.35 编译安装  [root@bogon pcre-8.35]# ./configure [root@bogon pcre-8.35]# make \u0026amp;\u0026amp; make install 查看pcre版本  [root@bogon pcre-8.35]# pcre-config --version 三. 安装OpenSSL\n 下载OpenSSL 安装包，下载地址：\rhttps://www.openssl.org/source/openssl-1.1.1h.tar.gz 解压安装包:  [root@bogon src]# tar -zxvf openssl-1.1.1h.tar.gz 进入安装包目录  [root@bogon src]# cd openssl-1.1.1h 编译安装  [root@bogon openssl-1.1.1h]# ./config --prefix=/usr/local/openssl [root@bogon openssl-1.1.1h]# make \u0026amp;\u0026amp; make install 查看OpenSSL版本  [root@bogon openssl-1.1.1h]# openssl version 可能出现的问题 使用openssl 命令提示命令不存在：openssl: command not found  解决方式：增加openssl的命令软连接，`ln -s /usr/local/openssl/bin/openssl /usr/bin/openssl`\r 使用openssl 命令报错：error while loading shared libraries: libssl.so.1.1: cannot open shared object file: No such file or directory  解决方式：\r```shell\recho \u0026quot;/usr/local/openssl/lib\u0026quot; \u0026gt;\u0026gt; /etc/ld.so.conf\rldconfig\r```\r 四. 安装 Nginx\n 下载 Nginx，下载地址：\rhttp://nginx.org/download/nginx-1.6.2.tar.gz  [root@bogon src]# cd /usr/local/src/ [root@bogon src]# wget http://nginx.org/download/nginx-1.6.2.tar.gz 解压安装包  [root@bogon src]# tar zxvf nginx-1.6.2.tar.gz 进入安装包目录  [root@bogon src]# cd nginx-1.6.2 编译安装  [root@bogon nginx-1.6.2]# ./configure --prefix=/usr/local/webserver/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/usr/local/src/pcre-8.35 --with-openssl=/usr/local/openssl [root@bogon nginx-1.6.2]# make [root@bogon nginx-1.6.2]# make install 查看nginx版本  [root@bogon nginx-1.6.2]# /usr/local/webserver/nginx/sbin/nginx -v 可能出现的问题 make 的时候出现  /bin/sh: line 2: ./config: No such file or directory make[1]: *** [/usr/local/openssl/.openssl/include/openssl/ssl.h] Error 127 make[1]: Leaving directory `/usr/local/src/nginx-1.18.0\u0026#39; make: *** [build] Error 2 路径错误导致。我们调整下nginx中openssl的配置/usr/local/src/nginx-1.18.0/auto/lib/openssl/conf，查找到如下配置\nCORE_INCS=\u0026#34;$CORE_INCS$OPENSSL/.openssl/include\u0026#34; CORE_DEPS=\u0026#34;$CORE_DEPS$OPENSSL/.openssl/include/openssl/ssl.h\u0026#34; CORE_LIBS=\u0026#34;$CORE_LIBS$OPENSSL/.openssl/lib/libssl.a\u0026#34; CORE_LIBS=\u0026#34;$CORE_LIBS$OPENSSL/.openssl/lib/libcrypto.a\u0026#34; 调整为\nCORE_INCS=\u0026#34;$CORE_INCS$OPENSSL/include\u0026#34; CORE_DEPS=\u0026#34;$CORE_DEPS$OPENSSL/include/openssl/ssl.h\u0026#34; CORE_LIBS=\u0026#34;$CORE_LIBS$OPENSSL/lib/libssl.a\u0026#34; CORE_LIBS=\u0026#34;$CORE_LIBS$OPENSSL/lib/libcrypto.a\u0026#34; 即删除.openssl/\n到此，nginx安装完成。\nNginx 配置\r#\r\r创建 Nginx 运行使用的用户 www：\n[root@bogon conf]# /usr/sbin/groupadd www  [root@bogon conf]# /usr/sbin/useradd -g www www 配置nginx.conf ，将/usr/local/webserver/nginx/conf/nginx.conf替换为以下内容\n[root@bogon conf]# cat /usr/local/webserver/nginx/conf/nginx.conf user www www; worker_processes 2; #设置值和CPU核心数一致 error_log /usr/local/webserver/nginx/logs/nginx_error.log crit; #日志位置和日志级别 pid /usr/local/webserver/nginx/nginx.pid; #Specifies the value for maximum file descriptors that can be opened by this process. worker_rlimit_nofile 65535; events { use epoll; worker_connections 65535; } http { include mime.types; default_type application/octet-stream; log_format main \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; $http_x_forwarded_for\u0026#39;; #charset gb2312; server_names_hash_bucket_size 128; client_header_buffer_size 32k; large_client_header_buffers 4 32k; client_max_body_size 8m; sendfile on; tcp_nopush on; keepalive_timeout 60; tcp_nodelay on; fastcgi_connect_timeout 300; fastcgi_send_timeout 300; fastcgi_read_timeout 300; fastcgi_buffer_size 64k; fastcgi_buffers 4 64k; fastcgi_busy_buffers_size 128k; fastcgi_temp_file_write_size 128k; gzip on; gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.0; gzip_comp_level 2; gzip_types text/plain application/x-javascript text/css application/xml; gzip_vary on; #limit_zone crawler $binary_remote_addr 10m; #下面是server虚拟主机的配置 server { listen 80;#监听端口 server_name localhost;#域名 index index.html index.htm index.php; root /usr/local/webserver/nginx/html;#站点目录 location ~ .*\\.(php|php5)?$ { #fastcgi_pass unix:/tmp/php-cgi.sock; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; include fastcgi.conf; } location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf|ico)$ { expires 30d; # access_log off; } location ~ .*\\.(js|css)?$ { expires 15d; # access_log off; } access_log off; } } 检查配置文件nginx.conf的正确性命令：\n[root@bogon conf]# /usr/local/webserver/nginx/sbin/nginx -t 启动 Nginx\r#\r\rNginx 启动命令如下：\n[root@bogon conf]# /usr/local/webserver/nginx/sbin/nginx 访问站点\n从浏览器访问我们配置的站点ip：\nNginx 其他命令\r#\r\r以下包含了 Nginx 常用的几个命令：\n/usr/local/webserver/nginx/sbin/nginx -s reload # 重新载入配置文件  /usr/local/webserver/nginx/sbin/nginx -s reopen # 重启 Nginx  /usr/local/webserver/nginx/sbin/nginx -s stop # 停止 Nginx "},{"id":14,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Linux%E7%9A%84%E8%99%9A%E6%8B%9FIP%E8%AE%BE%E7%BD%AE/","title":"Linux的虚拟IP设置","section":"网络与运维","content":"Linux的虚拟IP设置\r#\r\r2020-08-01 11:28\n在此之前对于虚拟IP的概念一直很模糊。这次，申请了两个服务器，三个IP，其中一个虚拟IP。本来想法是让网络组那边把虚拟IP绑定在F5设备上，然后对这两台服务器做负载均衡。\n结果，网络组说这个网络区域没有F5\u0026hellip;那只能自己搞起了。\n假设我们的服务器IP是172.23.15.10，虚拟IP为172.23.15.11，网卡名为ens192。网卡名可以通过ifconfig看到，通常有两个，一个以太网卡，一个本地网卡。\n第一个问题，虚拟IP怎么用？网卡是可以绑定多个IP的，通过如下命令绑定到以太网卡上\nifconfig ens192:1 172.23.15.11 netmask 255.255.252.0 broadcast 172.23.3.254 up\rroute add -host 172.23.15.11 dev ens192:1\r//ens192:1 为网络别名\r//netmask 为子网掩码\r//broadcast 为网关地址\r 这里我犯了一个低级错误。一开始错把虚拟ip绑定到本地网卡上。结果出现本机是可以ping通这个虚拟ip，但局域网内其他服务器ping不通该ip。\n 执行上述命令，其他机器就可以通过172.23.15.11来访问到172.23.15.10 这台机器了。\nPS. 卸载虚拟IP命令 ifconfig ens192:1 down\n"},{"id":15,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/%E8%AE%B0%E4%B8%80%E6%AC%A1%E8%A7%A3%E5%86%B3Telnet%E4%B8%8D%E9%80%9A%E9%97%AE%E9%A2%98%E7%9A%84%E7%BB%8F%E8%BF%87/","title":"记一次解决“Telnet不通”问题的经过","section":"网络与运维","content":"记一次解决“Telnet不通”问题的经过\r#\r\r2020-03-17 10:11\n有天，两台同一个网段的服务器：18和16，突然就出现18 telnet 不通16 的14267 端口的问题。\n这两台服务器的网络是互通的，这是可以保证的。\n在网络组同事的提示下，尝试用tcpdump抓包看下什么情况。\n在16上使用命令\n# tcpdump -i eno16780032 port 14267 and host 172.17.34.18\reno16780032 是16上的网口，监听18telnet 14267端口的发送过来数据包\n抓包如下，发现18发送数据了，但16并没有响应18。\n\r对比其他服务器telnet 16的14267端口，是三次握手成功的。\n\r用关键词“telnet 服务器 tcpdump 收到请求没有回复”查了一下。发现有个靠谱的博客\nlinux系统收到SYN但不回SYN+ACK问题排查\n对照18、16服务器的时间，发现18比16快了1秒多。 解决方案有两种\n 修正时间不准确的服务器 通过把16上的/proc/sys/net/ipv4/tcp_tw_recycle 的内容设置为0即可。  "},{"id":16,"href":"/docs/%E6%88%91%E7%88%B1%E7%BC%96%E7%A8%8B/Oracle_JDBC%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%87%A0%E7%A7%8D%E9%85%8D%E7%BD%AE%E5%86%99%E6%B3%95/","title":"Oracle JDBC连接的几种配置写法","section":"我爱编程","content":"Oracle JDBC连接的几种配置写法\r#\r\r2019-10-24 20:08\n今天上线项目的时候，发现Oracle的数据库连接一直有问题，报了这么一个错：\nORA-12505, TNS:listener does not currently know of SID given in connect descriptor 笔者的数据库写法是：jdbc:oracle:thin:@172.253.34.154:1521:eas\n这很奇怪，用客户端工具连接是没错的呀。纠结了好一会，突然灵光一闪：客户端工具配置的时候，用的是服务，而不是sid。难道服务跟sid的配置是不一样的？\n赶紧查下资料，果然！\n如果用的是服务名，配置是这样的：jdbc:oracle:thin:@//172.253.34.154:1521/eas\n而如果是sid，则配置是这样的：jdbc:oracle:thin:@172.253.34.154:1521:eas\n更新，问题修复！\n"},{"id":17,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/Linux_%E4%BF%AE%E6%94%B9DNS_%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%85%8D%E7%BD%AE/","title":"Linux 修改DNS 服务器配置","section":"网络与运维","content":"Linux 修改DNS 服务器配置\r#\r\r2019-07-04 09:02\n最近遇到个坑。\n修改DNS 服务器。随便一查，说是改/etc/resolv.conf，加上nameserver xxx.xxx.xxx.xxx即可。话不多说，改之，测试，生效。然后就没多管了。\n有一天，服务器重启了，然后DNS 解析失效了！一查，/etc/resolv.conf 之前的配置居然没了。不可思议，仔细一看，文件多了一行# Generated by NetworkManager。猜测是服务器重启之后重置了resolv.conf 文件。一顿查，终于发现修改DNS 服务器的正确姿势。\n# 查看配置文件。这个配置文件发现不同的机器上文件名并不一致，比如有些服务器会是`ifcfg-eno16780032`\rvi /etc/sysconfig/network-scripts/ifcfg-eth0\r# 添加DNS服务器地址到配置文件中\rDNS1=114.114.114.114\rDNS2=8.8.8.8\r# 重启网络服务\rservice network restart\r然后再查看/etc/resolv.conf，就会发现DNS配置已经被写进来了。\n"},{"id":18,"href":"/docs/%E7%BD%91%E7%BB%9C%E4%B8%8E%E8%BF%90%E7%BB%B4/CentOS_7.x_%E6%89%A9%E5%AE%B9/","title":"CentOS 7.x 扩容","section":"网络与运维","content":"CentOS 7.x 扩容\r#\r\r2018-12-10 11:02\nCentOS 增加磁盘之后，还需要对空间进行扩容。\n首先查看下系统现在的使用空间，发现只有50G左右。\n# df -lh\r再来看下已挂载的磁盘。\n# fdisk -l\r可以看到这么一个数据，说明现在挂载了一个53.7 GB的磁盘没用上。\nDisk /dev/sdb: 53.7 GB, 53687091200 bytes, 104857600 sectors\rUnits = sectors of 1 * 512 = 512 bytes\rSector size (logical/physical): 512 bytes / 512 bytes\rI/O size (minimum/optimal): 512 bytes / 512 bytes\r接下来对这个磁盘进行分区。\n# fdisk /dev/sdb\rWelcome to fdisk (util-linux 2.23.2).\rChanges will remain in memory only, until you decide to write them.\rBe careful before using the write command.\rDevice does not contain a recognized partition table\rBuilding a new DOS disklabel with disk identifier 0xe807ee1a.\rCommand (m for help): n\rPartition type:\rp primary (0 primary, 0 extended, 4 free)\re extended\rSelect (default p):\rUsing default response p\rPartition number (1-4, default 1):\rFirst sector (2048-104857599, default 2048):\rUsing default value 2048\rLast sector, +sectors or +size{K,M,G} (2048-104857599, default 104857599):\rUsing default value 104857599\rPartition 1 of type Linux and of size 50 GiB is set\rCommand 输入n，其它的都默认值即可。完成之后，再输入w进行写入操作。\n分区完毕，开始卷扩容，卷扩容使用lvm。\n# lvm\rlvm\u0026gt; pvcreate /dev/sdb1 //初始化刚刚的分区sdb1\rPhysical volume \u0026quot;/dev/sdb1\u0026quot; successfully created\rlvm\u0026gt; vgextend centos /dev/sdb1 //将刚初始化过的分区加入到虚拟卷组centos\rVolume group \u0026quot;centos\u0026quot; successfully extended\rlvm\u0026gt; vgdisplay -v\rUsing volume group(s) on command line.\rFound same device /dev/sda2 with same pvid eo1BSOY8EOTv6Q2XzBjI0chqCjZ7Lipo\rFound same device /dev/sdb1 with same pvid he5pJcr6EcrzyaNmdXM1TgLrtVwSp7W7\r--- Volume group ---\rVG Name centos //这就是虚拟卷组\rSystem ID\rFormat lvm2\rMetadata Areas 2\rMetadata Sequence No 4\rVG Access read/write\rVG Status resizable\rMAX LV 0\rCur LV 2\rOpen LV 2\rMax PV 0\rCur PV 2\rAct PV 2\rVG Size 99.50 GiB\rPE Size 4.00 MiB\rTotal PE 25473\rAlloc PE / Size 12674 / 49.51 GiB\rFree PE / Size 12799 / 50.00 GiB\r……\r使用vgdisplay -v ，注意看最后Free PE / Size 12799 / 50.00 GiB，这意味着我们可以进行扩容的空间，记下12799这个值。\nlvm\u0026gt; lvextend -l+12799 /dev/mapper/centos-root //扩容已有卷的容量\rSize of logical volume centos/root changed from 45.51 GiB (11650 extents) to 95.50 GiB (24449 extents).\rLogical volume root successfully resized.\rlvm\u0026gt; pvdisplay //查看卷容量\r--- Physical volume ---\rPV Name /dev/sda2\rVG Name centos\rPV Size 49.51 GiB / not usable 3.00 MiB\rAllocatable yes (but full)\rPE Size 4.00 MiB\rTotal PE 12674\rFree PE 0\rAllocated PE 12674\rPV UUID eo1BSO-Y8EO-Tv6Q-2XzB-jI0c-hqCj-Z7Lipo\r--- Physical volume ---\rPV Name /dev/sdb1\rVG Name centos\rPV Size 50.00 GiB / not usable 3.00 MiB\rAllocatable yes (but full)\rPE Size 4.00 MiB\rTotal PE 12799\rFree PE 0\rAllocated PE 12799\rPV UUID he5pJc-r6Ec-rzya-NmdX-M1Tg-LrtV-wSp7W7\r最后，文件系统扩容。/dev/mapper/centos-root是df -h查看到根目录的挂载点。\n# xfs_growfs /dev/mapper/centos-root\r CentOS 6.x这里使用的命令是resize2fs /dev/mapper/centos-root，有点不一样，注意下。\n 再次使用df -lh，跟文章开头相比。我们的空间已经增大了50G:-)\n/dev/mapper/centos-root 96G 1.7G 94G 2% /\r"}]